```markdown
# PDF Question Answering Application

This application allows you to ask questions about the content of a PDF document and receive answers generated by a Large Language Model (LLM). It leverages semantic similarity search to find relevant information within the PDF before feeding it to the LLM.

## How It Works

1.  **PDF Upload and Chunking:** The application takes a PDF file as input. It reads the text content of the PDF and splits it into smaller, manageable chunks.

2.  **Embedding Generation:** For each text chunk, the application uses a Sentence Transformer model from Hugging Face to generate vector embeddings. These embeddings capture the semantic meaning of each chunk.

3.  **Question Embedding:** When you ask a question, the same Sentence Transformer model generates a vector embedding for your question.

4.  **Semantic Similarity Search:** The application then performs a similarity search between the embedding of your question and the embeddings of all the PDF chunks. This identifies the chunks that are most semantically related to your question.

5.  **Contextualized LLM Generation:** The most relevant text chunks are then passed to an LLM (managed by Langchain) along with your question. The LLM uses this contextual information to generate a comprehensive and relevant answer.

6.  **Streamlit Interface:** The entire process is facilitated by a user-friendly graphical interface built using Streamlit.

## Deployed Application

You can try out the deployed application at: [https://pdfquestion-euvx4eayptjuxzvrht6wn5.streamlit.app/](https://pdfquestion-euvx4eayptjuxzvrht6wn5.streamlit.app/)

## Installation

To run this application locally, follow these steps:

1.  **Clone the repository:**
    ```bash
    git clone <YOUR_REPOSITORY_URL>
    cd <YOUR_REPOSITORY_NAME>
    ```
    *(Replace `<YOUR_REPOSITORY_URL>` and `<YOUR_REPOSITORY_NAME>` with the actual repository details)*

2.  **Install the required dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Configure Hugging Face API Key:**
    * Create a `.env` file in the root directory of the project.
    * Add your Hugging Face API key to the `.env` file as follows:
        ```
        HUGGINGFACE_API_KEY=YOUR_HUGGINGFACE_API_KEY
        ```
        *(Replace `YOUR_HUGGINGFACE_API_KEY` with your actual Hugging Face API key. You can obtain one from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))*

## Usage

1.  **Ensure Streamlit is installed:** If you haven't already, install Streamlit:
    ```bash
    pip install streamlit
    ```

2.  **Run the application:** Navigate to the root directory of the project in your terminal and run the following command:
    ```bash
    streamlit run app.py
    ```

3.  **Interact with the application:** A new tab will open in your web browser displaying the Streamlit application. You can then:
    * Upload a PDF file.
    * Ask questions related to the content of the uploaded PDF.
    * View the generated answers from the LLM.

## Technologies Used

* **Streamlit:** For creating the interactive web interface.
* **Langchain:** For managing the interaction with the Large Language Model.
* **Hugging Face Transformers:** For providing the Sentence Transformer model used for generating vector embeddings.
* **Python:** The primary programming language used for the application.

